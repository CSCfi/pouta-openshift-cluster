# Adapted from OpenShift Origin Prometheus example
kind: List
apiVersion: v1
items:
# Authorize the prometheus service account to read data about the cluster
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: prometheus
    namespace: monitoring-infra

- apiVersion: v1
  kind: ClusterRoleBinding
  metadata:
    name: prometheus-cluster-reader
  roleRef:
    name: cluster-reader
  subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: monitoring-infra

# Create an edge terminated route for Prometheus
- apiVersion: v1
  kind: Route
  metadata:
    name: prometheus
    namespace: monitoring-infra
  spec:
    host: "prometheus.{{ openshift_public_hostname }}"
    to:
      name: prometheus
    tls:
      termination: Edge

# Create a service for Prometheus (only targeting the nginx proxy port)
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      name: prometheus
    name: prometheus
    namespace: monitoring-infra
  spec:
    ports:
    - name: prometheus
      port: 8888
      protocol: TCP
      targetPort: 8888
    selector:
      app: prometheus

# Deploy Prometheus with basic-auth-proxy as side-car container.
# We deploy the pod on masters (running only our infrastructure pods).
# Prometheus is set to listen to 0.0.0.0:8080 so that readiness probe can
# poll the api without authentication (only proxied port 8888 is exposed with
# service and route, though)
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: prometheus
    name: prometheus
    namespace: monitoring-infra
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: prometheus
    template:
      metadata:
        labels:
          app: prometheus
        name: prometheus
      spec:
        nodeSelector:
          type: master
        serviceAccountName: prometheus
        containers:
        - name: basic-auth-proxy
          image: {{ monitoring_basic_auth_proxy_image }}
          imagePullPolicy: Always
          ports:
          - containerPort: 8888
            name: web
          volumeMounts:
          - mountPath: /etc/nginx/secrets
            name: monitoring-token
          resources:
            limits:
              cpu: "200m"
              memory: "256Mi"
          readinessProbe:
            tcpSocket:
              port: 8888
        - name: prometheus
          args:
          - --storage.tsdb.retention=6h
          - --config.file=/etc/prometheus/prometheus.yml
          - --web.listen-address=0.0.0.0:8080
          image: {{ monitoring_prometheus_image }}
          imagePullPolicy: Always
          volumeMounts:
          - mountPath: /etc/prometheus
            name: config-volume
          - mountPath: /prometheus
            name: data-volume
          resources:
            limits:
              cpu: "1000m"
              memory: "{{ prometheus_container_mem_limit|default('1024Mi') }}"
          readinessProbe:
            httpGet:
              path: /status
              port: 8080
              scheme: HTTP
        restartPolicy: Always
        volumes:
        - name: config-volume
          configMap:
            defaultMode: 420
            name: prometheus
        - name: data-volume
{% if skip_pvc|default(false) %}
          emptyDir: {}
{% else %}
          persistentVolumeClaim:
            claimName: "prometheus-data"
{% endif %}
        - name: monitoring-token
          secret:
            secretName: monitoring-token

# Define K8s scrape configuration for Prometheus
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: prometheus
    namespace: monitoring-infra
  data:
    prometheus.yml: |
      # A scrape configuration for running Prometheus on a Kubernetes cluster.
      # This uses separate scrape configs for cluster components (i.e. API server, node)
      # and services to allow each to use different authentication configs.
      #
      # Kubernetes labels will be added as Prometheus labels on metrics via the
      # `labelmap` relabeling action.

      # Scrape config for API servers.
      #
      # Kubernetes exposes API servers as endpoints to the default/kubernetes
      # service so this uses `endpoints` role and uses relabelling to only keep
      # the endpoints associated with the default/kubernetes service using the
      # default named port `https`. This works for single API server deployments as
      # well as HA API server deployments.
      scrape_configs:
      - job_name: 'kubernetes-apiservers'

        kubernetes_sd_configs:
        - role: endpoints

        # Default to scraping over https. If required, just disable this or change to
        # `http`.
        scheme: https

        # This TLS & bearer token file config is used to connect to the actual scrape
        # endpoints for cluster components. This is separate to discovery auth
        # configuration because discovery & scraping are two separate concerns in
        # Prometheus. The discovery auth config is automatic if Prometheus runs inside
        # the cluster. Otherwise, more config options have to be provided within the
        # <kubernetes_sd_config>.
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          # If your node certificates are self-signed or use a different CA to the
          # master CA, then disable certificate verification below. Note that
          # certificate verification is an integral part of a secure infrastructure
          # so this should only be disabled in a controlled environment. You can
          # disable certificate verification by uncommenting the line below.
          #
          # insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # Keep only the default/kubernetes service endpoints for the https port. This
        # will add targets for each API server which Kubernetes adds an endpoint to
        # the default/kubernetes service.
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'

        # Default to scraping over https. If required, just disable this or change to
        # `http`.
        scheme: https

        # This TLS & bearer token file config is used to connect to the actual scrape
        # endpoints for cluster components. This is separate to discovery auth
        # configuration because discovery & scraping are two separate concerns in
        # Prometheus. The discovery auth config is automatic if Prometheus runs inside
        # the cluster. Otherwise, more config options have to be provided within the
        # <kubernetes_sd_config>.
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          # If your node certificates are self-signed or use a different CA to the
          # master CA, then disable certificate verification below. Note that
          # certificate verification is an integral part of a secure infrastructure
          # so this should only be disabled in a controlled environment. You can
          # disable certificate verification by uncommenting the line below.
          #
          # insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs:
        - role: node

        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)

      # Scrape config for service endpoints.
      #
      # The relabeling allows the actual service scrape endpoint to be configured
      # via the following annotations:
      #
      # * `prometheus.io/scrape`: Only scrape services that have a value of `true`
      # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
      # to set this to `https` & most likely set the `tls_config` of the scrape config.
      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
      # * `prometheus.io/port`: If the metrics are exposed on a different port to the
      # service then set this appropriately.
      - job_name: 'kubernetes-service-endpoints'

        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          # TODO: this should be per target
          insecure_skip_verify: true

        kubernetes_sd_configs:
        - role: endpoints

        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
          action: replace
          target_label: __scheme__
          regex: (https?)
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          target_label: __address__
          regex: (.+)(?::\d+);(\d+)
          replacement: $1:$2
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_username]
          action: replace
          target_label: __basic_auth_username__
          regex: (.+)
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_password]
          action: replace
          target_label: __basic_auth_password__
          regex: (.+)
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          action: replace
          target_label: kubernetes_name
